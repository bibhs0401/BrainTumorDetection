{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "connect google colab with google drive"
      ],
      "metadata": {
        "id": "zAtyab7xxa_d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YgVOPMFH-rdy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6b9e533-bee8-4ad7-9b17-42aa1053f7c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#connect google colab with google drive\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import the libraries to load dataset\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "#opens file in readmode\n",
        "zip_ref = zipfile.ZipFile('/content/gdrive/MyDrive/MajorProject/br35hdataset/train.zip')\n",
        "\n",
        "#extracts the files into the /MajorProject folder\n",
        "zip_ref.extractall('/content/gdrive/MyDrive/MajorProject/br35hdataset')\n",
        "\n",
        "#close the file\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "u6i5i4GCnCZK"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import the libraries to load dataset\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "#opens file in readmode\n",
        "zip_ref = zipfile.ZipFile('/content/gdrive/MyDrive/MajorProject/br35hdataset/validation.zip')\n",
        "\n",
        "#extracts the files into the /MajorProject folder\n",
        "zip_ref.extractall('/content/gdrive/MyDrive/MajorProject/br35hdataset')\n",
        "\n",
        "#close the file\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "13t41rtVnRnM"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import the libraries to load dataset\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "#opens file in readmode\n",
        "zip_ref = zipfile.ZipFile('/content/gdrive/MyDrive/MajorProject/br35hdataset/test.zip')\n",
        "\n",
        "#extracts the files into the /MajorProject folder\n",
        "zip_ref.extractall('/content/gdrive/MyDrive/MajorProject/br35hdataset')\n",
        "\n",
        "#close the file\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "e8xZK5-tnUez"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import models, layers\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import Conv2D, Input, ZeroPadding2D, BatchNormalization, Activation, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
        "#from sklearn.model_selection import train_test_split\n",
        "#from sklearn.metrics import f1_score\n",
        "#from sklearn.utils import shuffle\n",
        "import cv2\n",
        "import imutils\n",
        "import numpy as np\n",
        "import time\n",
        "import sys\n",
        "import math\n",
        "import os \n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from sklearn import svm"
      ],
      "metadata": {
        "id": "mNMIqf1bHC4W"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#initializing variables\n",
        "BATCH_SIZE = 32\n",
        "IMAGE_SIZE = 256\n",
        "CHANNELS=3\n",
        "EPOCHS=30\n",
        "num_classes=2"
      ],
      "metadata": {
        "id": "O4VRYxPPIHmQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Enable eager execution\n",
        "tf.config.run_functions_eagerly(True)"
      ],
      "metadata": {
        "id": "rO7JhvqaBR-A"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to preprocess image\n",
        "def preprocess_image(image_path):\n",
        "    # Read image\n",
        "    image = cv2.imread(image_path)\n",
        "    # Convert image to grayscale\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    # Blur image\n",
        "    blurred_image = cv2.GaussianBlur(gray_image, (5, 5), 0)\n",
        "    # Threshold image to binary\n",
        "    _, threshold_image = cv2.threshold(blurred_image, 0, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
        "    # Erosion and Dilation for noise removal\n",
        "    kernel = np.ones((5,5), np.uint8)\n",
        "    opening = cv2.morphologyEx(threshold_image, cv2.MORPH_OPEN, kernel)\n",
        "    # Find contours and select the largest contour\n",
        "    contours, _ = cv2.findContours(opening, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    largest_contour = max(contours, key=cv2.contourArea)\n",
        "    # Calculate extreme points of the contour\n",
        "    leftmost = tuple(largest_contour[largest_contour[:,:,0].argmin()][0])\n",
        "    rightmost = tuple(largest_contour[largest_contour[:,:,0].argmax()][0])\n",
        "    topmost = tuple(largest_contour[largest_contour[:,:,1].argmin()][0])\n",
        "    bottommost = tuple(largest_contour[largest_contour[:,:,1].argmax()][0])\n",
        "    # Crop image using contour and extreme points\n",
        "    cropped_image = image[topmost[1]:bottommost[1], leftmost[0]:rightmost[0]]\n",
        "    # Resize cropped image using bicubic interpolation\n",
        "    resized_image = cv2.resize(cropped_image, (256, 256), interpolation=cv2.INTER_CUBIC)\n",
        "    # Return preprocessed image\n",
        "    return resized_image"
      ],
      "metadata": {
        "id": "4buEKYE8O5ke"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to read images from directory and preprocess them\n",
        "def preprocess_images(directory):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for subdirectory in os.listdir(directory):\n",
        "        subdirectory_path = os.path.join(directory, subdirectory)\n",
        "        if os.path.isdir(subdirectory_path):\n",
        "            for image_filename in os.listdir(subdirectory_path):\n",
        "                image_path = os.path.join(subdirectory_path, image_filename)\n",
        "                # Preprocess image and append to list\n",
        "                preprocessed_image = preprocess_image(image_path)\n",
        "                images.append(preprocessed_image)\n",
        "                # Append label based on subdirectory name\n",
        "                if subdirectory == 'yes':\n",
        "                    labels.append(1)\n",
        "                else:\n",
        "                    labels.append(0)\n",
        "    # Convert images and labels to numpy arrays\n",
        "    images = np.array(images)\n",
        "    labels = np.array(labels)\n",
        "    # Return preprocessed images and labels\n",
        "    return images, labels"
      ],
      "metadata": {
        "id": "Kgh3YIjoFaXk"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_directory = '/content/gdrive/MyDrive/MajorProject/br35hdataset/train'\n",
        "validation_directory = '/content/gdrive/MyDrive/MajorProject/br35hdataset/validation'\n",
        "test_directory = '/content/gdrive/MyDrive/MajorProject/br35hdataset/test'\n",
        "\n",
        "train_images, train_labels = preprocess_images(train_directory)\n",
        "test_images, test_labels = preprocess_images(test_directory)\n",
        "validation_images, validation_labels = preprocess_images(validation_directory)\n"
      ],
      "metadata": {
        "id": "MURWy4hrUBX3"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create CNN model\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, kernel_size = (3,3), activation='relu',input_shape=(IMAGE_SIZE, IMAGE_SIZE,CHANNELS)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Dropout(rate=0.2),\n",
        "    layers.Conv2D(64, kernel_size = (3,3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Dropout(rate=0.2),\n",
        "    layers.Conv2D(128, kernel_size = (3,3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Dropout(rate=0.2),\n",
        "    layers.Conv2D(128, kernel_size = (3,3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Dropout(rate=0.2),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dropout(rate=0.2),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "exlc_t7HVJco"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "ujR3eYbX3QKm"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkZEuDpy6eGC",
        "outputId": "32cb40a6-98b1-4130-fb1e-107f80c5d227"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 254, 254, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 127, 127, 32)     0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 127, 127, 32)      0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 125, 125, 64)      18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 62, 62, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 62, 62, 64)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 60, 60, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 30, 30, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 30, 30, 128)       0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 28, 28, 128)       147584    \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 14, 14, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 14, 14, 128)       0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               3211392   \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,452,353\n",
            "Trainable params: 3,452,353\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# define the path and filename to save the model weights\n",
        "filepath = \"/content/gdrive/MyDrive/MajorProject/br35hdataset/weights_cnn_svm.h5\"\n",
        "\n",
        "# create a ModelCheckpoint callback to save the best model weights during training\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')"
      ],
      "metadata": {
        "id": "MWB1E4UtWmv8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model on preprocessed images and labels\n",
        "model.fit(train_images, train_labels, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_data=(validation_images, validation_labels))\n",
        "\n"
      ],
      "metadata": {
        "id": "0YyqUDoO0qqE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e7a8b45-5712-438f-ace1-25775704bd69"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/structured_function.py:256: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "450/450 [==============================] - 75s 148ms/step - loss: 5.3821 - accuracy: 0.7247 - val_loss: 0.5136 - val_accuracy: 0.7667\n",
            "Epoch 2/30\n",
            "450/450 [==============================] - 66s 146ms/step - loss: 0.4471 - accuracy: 0.7842 - val_loss: 0.3746 - val_accuracy: 0.8306\n",
            "Epoch 3/30\n",
            "450/450 [==============================] - 65s 145ms/step - loss: 0.3767 - accuracy: 0.8314 - val_loss: 0.3086 - val_accuracy: 0.8689\n",
            "Epoch 4/30\n",
            "450/450 [==============================] - 66s 146ms/step - loss: 0.3069 - accuracy: 0.8656 - val_loss: 0.2777 - val_accuracy: 0.8789\n",
            "Epoch 5/30\n",
            "450/450 [==============================] - 66s 146ms/step - loss: 0.2642 - accuracy: 0.8878 - val_loss: 0.2468 - val_accuracy: 0.9011\n",
            "Epoch 6/30\n",
            "450/450 [==============================] - 65s 146ms/step - loss: 0.2311 - accuracy: 0.9062 - val_loss: 0.2119 - val_accuracy: 0.9106\n",
            "Epoch 7/30\n",
            "450/450 [==============================] - 66s 146ms/step - loss: 0.1892 - accuracy: 0.9274 - val_loss: 0.1733 - val_accuracy: 0.9383\n",
            "Epoch 8/30\n",
            "450/450 [==============================] - 66s 146ms/step - loss: 0.1717 - accuracy: 0.9348 - val_loss: 0.2015 - val_accuracy: 0.9233\n",
            "Epoch 9/30\n",
            "450/450 [==============================] - 65s 145ms/step - loss: 0.1449 - accuracy: 0.9469 - val_loss: 0.1606 - val_accuracy: 0.9500\n",
            "Epoch 10/30\n",
            "450/450 [==============================] - 66s 146ms/step - loss: 0.1390 - accuracy: 0.9474 - val_loss: 0.1628 - val_accuracy: 0.9450\n",
            "Epoch 11/30\n",
            "450/450 [==============================] - 65s 144ms/step - loss: 0.1311 - accuracy: 0.9524 - val_loss: 0.1458 - val_accuracy: 0.9489\n",
            "Epoch 12/30\n",
            "450/450 [==============================] - 65s 144ms/step - loss: 0.1130 - accuracy: 0.9573 - val_loss: 0.1339 - val_accuracy: 0.9533\n",
            "Epoch 13/30\n",
            "450/450 [==============================] - 64s 143ms/step - loss: 0.1079 - accuracy: 0.9623 - val_loss: 0.1457 - val_accuracy: 0.9544\n",
            "Epoch 14/30\n",
            "450/450 [==============================] - 64s 143ms/step - loss: 0.1032 - accuracy: 0.9653 - val_loss: 0.1715 - val_accuracy: 0.9467\n",
            "Epoch 15/30\n",
            "450/450 [==============================] - 64s 143ms/step - loss: 0.0969 - accuracy: 0.9631 - val_loss: 0.1428 - val_accuracy: 0.9517\n",
            "Epoch 16/30\n",
            "450/450 [==============================] - 64s 143ms/step - loss: 0.0932 - accuracy: 0.9662 - val_loss: 0.1217 - val_accuracy: 0.9644\n",
            "Epoch 17/30\n",
            "450/450 [==============================] - 64s 141ms/step - loss: 0.0848 - accuracy: 0.9694 - val_loss: 0.1620 - val_accuracy: 0.9439\n",
            "Epoch 18/30\n",
            "450/450 [==============================] - 63s 141ms/step - loss: 0.0862 - accuracy: 0.9686 - val_loss: 0.1075 - val_accuracy: 0.9700\n",
            "Epoch 19/30\n",
            "450/450 [==============================] - 63s 140ms/step - loss: 0.0880 - accuracy: 0.9676 - val_loss: 0.1630 - val_accuracy: 0.9444\n",
            "Epoch 20/30\n",
            "450/450 [==============================] - 62s 138ms/step - loss: 0.0890 - accuracy: 0.9693 - val_loss: 0.1284 - val_accuracy: 0.9628\n",
            "Epoch 21/30\n",
            "450/450 [==============================] - 63s 139ms/step - loss: 0.0795 - accuracy: 0.9726 - val_loss: 0.1239 - val_accuracy: 0.9617\n",
            "Epoch 22/30\n",
            "450/450 [==============================] - 62s 138ms/step - loss: 0.0753 - accuracy: 0.9738 - val_loss: 0.1629 - val_accuracy: 0.9600\n",
            "Epoch 23/30\n",
            "450/450 [==============================] - 61s 137ms/step - loss: 0.0700 - accuracy: 0.9772 - val_loss: 0.1210 - val_accuracy: 0.9661\n",
            "Epoch 24/30\n",
            "450/450 [==============================] - 62s 137ms/step - loss: 0.0696 - accuracy: 0.9758 - val_loss: 0.1627 - val_accuracy: 0.9528\n",
            "Epoch 25/30\n",
            "450/450 [==============================] - 60s 134ms/step - loss: 0.0836 - accuracy: 0.9718 - val_loss: 0.1293 - val_accuracy: 0.9611\n",
            "Epoch 26/30\n",
            "450/450 [==============================] - 60s 134ms/step - loss: 0.0644 - accuracy: 0.9784 - val_loss: 0.1590 - val_accuracy: 0.9544\n",
            "Epoch 27/30\n",
            "450/450 [==============================] - 60s 133ms/step - loss: 0.0739 - accuracy: 0.9751 - val_loss: 0.1127 - val_accuracy: 0.9672\n",
            "Epoch 28/30\n",
            "450/450 [==============================] - 60s 133ms/step - loss: 0.0585 - accuracy: 0.9800 - val_loss: 0.1093 - val_accuracy: 0.9750\n",
            "Epoch 29/30\n",
            "450/450 [==============================] - 60s 134ms/step - loss: 0.0685 - accuracy: 0.9785 - val_loss: 0.1257 - val_accuracy: 0.9628\n",
            "Epoch 30/30\n",
            "450/450 [==============================] - 60s 133ms/step - loss: 0.0582 - accuracy: 0.9804 - val_loss: 0.1179 - val_accuracy: 0.9694\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f44ea691610>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model\n",
        "model.save('/content/gdrive/MyDrive/MajorProject/br35hdataset/imagepreprocess_cnn.h5')"
      ],
      "metadata": {
        "id": "c2leFRFHQxFG"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model on test set\n",
        "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
        "print('Test accuracy:', test_accuracy)"
      ],
      "metadata": {
        "id": "hWT7rKlwH9R3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d8ebb57-b926-40cf-c918-9cc2509544a6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "57/57 [==============================] - 2s 42ms/step - loss: 0.1400 - accuracy: 0.9639\n",
            "Test accuracy: 0.9638888835906982\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "# Load saved CNN model\n",
        "cnn_model = load_model('/content/gdrive/MyDrive/MajorProject/br35hdataset/imagepreprocess_cnn.h5')"
      ],
      "metadata": {
        "id": "ZeiqOH_FxAdB"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import svm\n",
        "\n",
        "# Extract features using CNN model\n",
        "train_features = cnn_model.predict(train_images)\n",
        "test_features = cnn_model.predict(test_images)\n",
        "validation_features = cnn_model.predict(validation_images)\n",
        "\n",
        "# Train SVM classifier using CNN features\n",
        "clf = svm.SVC()\n",
        "clf.fit(train_features, train_labels)\n",
        "\n",
        "# Evaluate SVM classifier on test set\n",
        "accuracy = clf.score(test_features, test_labels)\n",
        "print('Accuracy:', accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NgpZRFyNzmKK",
        "outputId": "580ea97a-ef24-447f-a742-2578c9424ef6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/structured_function.py:256: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "450/450 [==============================] - 20s 31ms/step\n",
            "57/57 [==============================] - 2s 33ms/step\n",
            "57/57 [==============================] - 2s 29ms/step\n",
            "Accuracy: 0.9655555555555555\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "# Save SVM classifier\n",
        "with open('/content/gdrive/MyDrive/MajorProject/br35hdataset/svm_model.pkl', 'wb') as f:\n",
        "    pickle.dump(clf, f)"
      ],
      "metadata": {
        "id": "jWbSnueC2tOH"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load SVM classifier\n",
        "with open('/content/gdrive/MyDrive/MajorProject/br35hdataset/svm_model.pkl', 'rb') as f:\n",
        "    svm_classifier = pickle.load(f)"
      ],
      "metadata": {
        "id": "2ISGtHwU0Hfx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VAu5WCbu0IXF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}