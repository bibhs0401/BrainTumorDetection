{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zu6-ZOS9-zgi",
        "outputId": "50beb1b2-eb28-4677-e99f-b8233b44e209"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "#connect google colab with google drive\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import models, layers\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import Conv2D, Input, ZeroPadding2D, BatchNormalization, Activation, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
        "#from sklearn.model_selection import train_test_split\n",
        "#from sklearn.metrics import f1_score\n",
        "#from sklearn.utils import shuffle\n",
        "import cv2\n",
        "import imutils\n",
        "import numpy as np\n",
        "import time\n",
        "import sys\n",
        "import math\n",
        "#from os import listdir\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras.applications import InceptionV3"
      ],
      "metadata": {
        "id": "xSnH5Fq3--Mb"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#initializing variables\n",
        "BATCH_SIZE = 32\n",
        "IMAGE_SIZE = 299\n",
        "CHANNELS=3\n",
        "EPOCHS=50\n",
        "num_classes=2"
      ],
      "metadata": {
        "id": "00_o6cIh_20-"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import models, layers\n",
        "\n",
        "#input_shape = (BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, CHANNELS)\n",
        "\n",
        "train_data_dir = '/content/gdrive/MyDrive/MajorProject/br35hdataset/train'\n",
        "validation_data_dir = '/content/gdrive/MyDrive/MajorProject/br35hdataset/validation'\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,\n",
        "    rescale=1./255    \n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    preprocessing_function=preprocess_input\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "validation_generator = val_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICvzjuu6ALvQ",
        "outputId": "7d882950-47a8-4f83-a83a-0004ef7a0868"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 14400 images belonging to 2 classes.\n",
            "Found 1800 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import required libraries\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Define input shape\n",
        "img_width, img_height = 299, 299\n",
        "input_shape = (img_width, img_height, 3)\n",
        "\n",
        "# Load InceptionV3 model with pre-trained weights from ImageNet\n",
        "inception = InceptionV3(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "\n",
        "# Freeze the pre-trained layers\n",
        "for layer in inception.layers:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "id": "b6qdKvqibQCt"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "# Add the InceptionV3 model as the first layer\n",
        "model.add(inception)\n",
        "\n",
        "# Add a Flatten layer to convert the output of the Inception V3 model to a 1D vector\n",
        "#model.add(Flatten(input_shape=inception.output_shape[1:]))\n",
        "model.add(Flatten())\n",
        "\n",
        "# Add a Dense layer with 256 units and ReLU activation\n",
        "model.add(Dense(256, activation='relu'))\n",
        "\n",
        "# Add a Dropout layer to prevent overfitting\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# Add the final Dense layer with 2 units and softmax activation for binary classification\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "# Reshape the output of the InceptionV3 model to match the input shape of the custom model\n",
        "x = inception.output\n",
        "x = Flatten()(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dropout(0.2)(x)\n",
        "predictions = Dense(2, activation='softmax')(x)"
      ],
      "metadata": {
        "id": "Hiq2Y996fU8n"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# concatenate the Inception V3 model with the custom model\n",
        "model = Model(inputs=inception.input, outputs=predictions)\n",
        "\n",
        "# compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "jdQo1taHii6i"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    validation_data=validation_generator,\n",
        "    verbose=1,\n",
        "    epochs=EPOCHS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROmPkic_i1j4",
        "outputId": "a892428d-e6e7-45cf-c80c-0a8c2ed2b8e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "  3/450 [..............................] - ETA: 1:15:29 - loss: 10.6954 - accuracy: 0.5312"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the test folder\n",
        "test_data_dir = '/content/gdrive/MyDrive/MajorProject/br35hdataset/test'\n",
        "\n",
        "test_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    preprocessing_function=preprocess_input\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_data_dir,\n",
        "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")"
      ],
      "metadata": {
        "id": "b-OvwMJFjAQc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the model on the test set\n",
        "score = model.evaluate_generator(test_generator)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "id": "NlzBm-hni8Hk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}