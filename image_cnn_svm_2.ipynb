{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "connect google colab with google drive"
      ],
      "metadata": {
        "id": "zAtyab7xxa_d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YgVOPMFH-rdy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eaa81f53-d0dd-44c9-cae1-1b27904ce525"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "#connect google colab with google drive\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import the libraries to load dataset\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "#opens file in readmode\n",
        "zip_ref = zipfile.ZipFile('/content/gdrive/MyDrive/MajorProject/br35hdataset/train.zip')\n",
        "\n",
        "#extracts the files into the /MajorProject folder\n",
        "zip_ref.extractall('/content/gdrive/MyDrive/MajorProject/br35hdataset')\n",
        "\n",
        "#close the file\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "u6i5i4GCnCZK"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import the libraries to load dataset\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "#opens file in readmode\n",
        "zip_ref = zipfile.ZipFile('/content/gdrive/MyDrive/MajorProject/br35hdataset/validation.zip')\n",
        "\n",
        "#extracts the files into the /MajorProject folder\n",
        "zip_ref.extractall('/content/gdrive/MyDrive/MajorProject/br35hdataset')\n",
        "\n",
        "#close the file\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "13t41rtVnRnM"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import the libraries to load dataset\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "#opens file in readmode\n",
        "zip_ref = zipfile.ZipFile('/content/gdrive/MyDrive/MajorProject/br35hdataset/test.zip')\n",
        "\n",
        "#extracts the files into the /MajorProject folder\n",
        "zip_ref.extractall('/content/gdrive/MyDrive/MajorProject/br35hdataset')\n",
        "\n",
        "#close the file\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "e8xZK5-tnUez"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import models, layers\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import Conv2D, Input, ZeroPadding2D, BatchNormalization, Activation, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
        "#from sklearn.model_selection import train_test_split\n",
        "#from sklearn.metrics import f1_score\n",
        "#from sklearn.utils import shuffle\n",
        "import cv2\n",
        "import imutils\n",
        "import numpy as np\n",
        "import time\n",
        "import sys\n",
        "import math\n",
        "import os \n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from sklearn import svm"
      ],
      "metadata": {
        "id": "mNMIqf1bHC4W"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#initializing variables\n",
        "BATCH_SIZE = 32\n",
        "IMAGE_SIZE = 256\n",
        "CHANNELS=3\n",
        "EPOCHS=30\n",
        "num_classes=2"
      ],
      "metadata": {
        "id": "O4VRYxPPIHmQ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Enable eager execution\n",
        "tf.config.run_functions_eagerly(True)"
      ],
      "metadata": {
        "id": "rO7JhvqaBR-A"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to preprocess image\n",
        "def preprocess_image(image_path):\n",
        "    # Read image\n",
        "    image = cv2.imread(image_path)\n",
        "    # Convert image to grayscale\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    # Blur image\n",
        "    blurred_image = cv2.GaussianBlur(gray_image, (5, 5), 0)\n",
        "    # Threshold image to binary\n",
        "    _, threshold_image = cv2.threshold(blurred_image, 0, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
        "    # Erosion and Dilation for noise removal\n",
        "    kernel = np.ones((5,5), np.uint8)\n",
        "    opening = cv2.morphologyEx(threshold_image, cv2.MORPH_OPEN, kernel)\n",
        "    # Find contours and select the largest contour\n",
        "    contours, _ = cv2.findContours(opening, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    largest_contour = max(contours, key=cv2.contourArea)\n",
        "    # Calculate extreme points of the contour\n",
        "    leftmost = tuple(largest_contour[largest_contour[:,:,0].argmin()][0])\n",
        "    rightmost = tuple(largest_contour[largest_contour[:,:,0].argmax()][0])\n",
        "    topmost = tuple(largest_contour[largest_contour[:,:,1].argmin()][0])\n",
        "    bottommost = tuple(largest_contour[largest_contour[:,:,1].argmax()][0])\n",
        "    # Crop image using contour and extreme points\n",
        "    cropped_image = image[topmost[1]:bottommost[1], leftmost[0]:rightmost[0]]\n",
        "    # Resize cropped image using bicubic interpolation\n",
        "    resized_image = cv2.resize(cropped_image, (256, 256), interpolation=cv2.INTER_CUBIC)\n",
        "    # Return preprocessed image\n",
        "    return resized_image"
      ],
      "metadata": {
        "id": "4buEKYE8O5ke"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to read images from directory and preprocess them\n",
        "def preprocess_images(directory):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for subdirectory in os.listdir(directory):\n",
        "        subdirectory_path = os.path.join(directory, subdirectory)\n",
        "        if os.path.isdir(subdirectory_path):\n",
        "            for image_filename in os.listdir(subdirectory_path):\n",
        "                image_path = os.path.join(subdirectory_path, image_filename)\n",
        "                # Preprocess image and append to list\n",
        "                preprocessed_image = preprocess_image(image_path)\n",
        "                images.append(preprocessed_image)\n",
        "                # Append label based on subdirectory name\n",
        "                if subdirectory == 'yes':\n",
        "                    labels.append(1)\n",
        "                else:\n",
        "                    labels.append(0)\n",
        "    # Convert images and labels to numpy arrays\n",
        "    images = np.array(images)\n",
        "    labels = np.array(labels)\n",
        "    # Return preprocessed images and labels\n",
        "    return images, labels"
      ],
      "metadata": {
        "id": "Kgh3YIjoFaXk"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_directory = '/content/gdrive/MyDrive/MajorProject/br35hdataset/train'\n",
        "validation_directory = '/content/gdrive/MyDrive/MajorProject/br35hdataset/validation'\n",
        "test_directory = '/content/gdrive/MyDrive/MajorProject/br35hdataset/test'\n",
        "\n",
        "train_images, train_labels = preprocess_images(train_directory)\n",
        "test_images, test_labels = preprocess_images(test_directory)\n",
        "validation_images, validation_labels = preprocess_images(validation_directory)\n"
      ],
      "metadata": {
        "id": "MURWy4hrUBX3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create CNN model\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, kernel_size = (3,3), activation='relu',input_shape=(IMAGE_SIZE, IMAGE_SIZE,CHANNELS)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Dropout(rate=0.2),\n",
        "    layers.Conv2D(64, kernel_size = (3,3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Dropout(rate=0.2),\n",
        "    layers.Conv2D(128, kernel_size = (3,3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Dropout(rate=0.2),\n",
        "    layers.Conv2D(128, kernel_size = (3,3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Dropout(rate=0.2),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dropout(rate=0.2),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "exlc_t7HVJco"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "ujR3eYbX3QKm"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkZEuDpy6eGC",
        "outputId": "32cb40a6-98b1-4130-fb1e-107f80c5d227"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 254, 254, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 127, 127, 32)     0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 127, 127, 32)      0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 125, 125, 64)      18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 62, 62, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 62, 62, 64)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 60, 60, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 30, 30, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 30, 30, 128)       0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 28, 28, 128)       147584    \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 14, 14, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 14, 14, 128)       0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               3211392   \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,452,353\n",
            "Trainable params: 3,452,353\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# define the path and filename to save the model weights\n",
        "filepath = \"/content/gdrive/MyDrive/MajorProject/br35hdataset/weights_cnn_svm.h5\"\n",
        "\n",
        "# create a ModelCheckpoint callback to save the best model weights during training\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')"
      ],
      "metadata": {
        "id": "MWB1E4UtWmv8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model on preprocessed images and labels\n",
        "model.fit(train_images, train_labels, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_data=(validation_images, validation_labels))\n",
        "\n"
      ],
      "metadata": {
        "id": "0YyqUDoO0qqE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e7a8b45-5712-438f-ace1-25775704bd69"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/structured_function.py:256: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "450/450 [==============================] - 75s 148ms/step - loss: 5.3821 - accuracy: 0.7247 - val_loss: 0.5136 - val_accuracy: 0.7667\n",
            "Epoch 2/30\n",
            "450/450 [==============================] - 66s 146ms/step - loss: 0.4471 - accuracy: 0.7842 - val_loss: 0.3746 - val_accuracy: 0.8306\n",
            "Epoch 3/30\n",
            "450/450 [==============================] - 65s 145ms/step - loss: 0.3767 - accuracy: 0.8314 - val_loss: 0.3086 - val_accuracy: 0.8689\n",
            "Epoch 4/30\n",
            "450/450 [==============================] - 66s 146ms/step - loss: 0.3069 - accuracy: 0.8656 - val_loss: 0.2777 - val_accuracy: 0.8789\n",
            "Epoch 5/30\n",
            "450/450 [==============================] - 66s 146ms/step - loss: 0.2642 - accuracy: 0.8878 - val_loss: 0.2468 - val_accuracy: 0.9011\n",
            "Epoch 6/30\n",
            "450/450 [==============================] - 65s 146ms/step - loss: 0.2311 - accuracy: 0.9062 - val_loss: 0.2119 - val_accuracy: 0.9106\n",
            "Epoch 7/30\n",
            "450/450 [==============================] - 66s 146ms/step - loss: 0.1892 - accuracy: 0.9274 - val_loss: 0.1733 - val_accuracy: 0.9383\n",
            "Epoch 8/30\n",
            "450/450 [==============================] - 66s 146ms/step - loss: 0.1717 - accuracy: 0.9348 - val_loss: 0.2015 - val_accuracy: 0.9233\n",
            "Epoch 9/30\n",
            "450/450 [==============================] - 65s 145ms/step - loss: 0.1449 - accuracy: 0.9469 - val_loss: 0.1606 - val_accuracy: 0.9500\n",
            "Epoch 10/30\n",
            "450/450 [==============================] - 66s 146ms/step - loss: 0.1390 - accuracy: 0.9474 - val_loss: 0.1628 - val_accuracy: 0.9450\n",
            "Epoch 11/30\n",
            "450/450 [==============================] - 65s 144ms/step - loss: 0.1311 - accuracy: 0.9524 - val_loss: 0.1458 - val_accuracy: 0.9489\n",
            "Epoch 12/30\n",
            "450/450 [==============================] - 65s 144ms/step - loss: 0.1130 - accuracy: 0.9573 - val_loss: 0.1339 - val_accuracy: 0.9533\n",
            "Epoch 13/30\n",
            "450/450 [==============================] - 64s 143ms/step - loss: 0.1079 - accuracy: 0.9623 - val_loss: 0.1457 - val_accuracy: 0.9544\n",
            "Epoch 14/30\n",
            "450/450 [==============================] - 64s 143ms/step - loss: 0.1032 - accuracy: 0.9653 - val_loss: 0.1715 - val_accuracy: 0.9467\n",
            "Epoch 15/30\n",
            "450/450 [==============================] - 64s 143ms/step - loss: 0.0969 - accuracy: 0.9631 - val_loss: 0.1428 - val_accuracy: 0.9517\n",
            "Epoch 16/30\n",
            "450/450 [==============================] - 64s 143ms/step - loss: 0.0932 - accuracy: 0.9662 - val_loss: 0.1217 - val_accuracy: 0.9644\n",
            "Epoch 17/30\n",
            "450/450 [==============================] - 64s 141ms/step - loss: 0.0848 - accuracy: 0.9694 - val_loss: 0.1620 - val_accuracy: 0.9439\n",
            "Epoch 18/30\n",
            "450/450 [==============================] - 63s 141ms/step - loss: 0.0862 - accuracy: 0.9686 - val_loss: 0.1075 - val_accuracy: 0.9700\n",
            "Epoch 19/30\n",
            "450/450 [==============================] - 63s 140ms/step - loss: 0.0880 - accuracy: 0.9676 - val_loss: 0.1630 - val_accuracy: 0.9444\n",
            "Epoch 20/30\n",
            "450/450 [==============================] - 62s 138ms/step - loss: 0.0890 - accuracy: 0.9693 - val_loss: 0.1284 - val_accuracy: 0.9628\n",
            "Epoch 21/30\n",
            "450/450 [==============================] - 63s 139ms/step - loss: 0.0795 - accuracy: 0.9726 - val_loss: 0.1239 - val_accuracy: 0.9617\n",
            "Epoch 22/30\n",
            "450/450 [==============================] - 62s 138ms/step - loss: 0.0753 - accuracy: 0.9738 - val_loss: 0.1629 - val_accuracy: 0.9600\n",
            "Epoch 23/30\n",
            "450/450 [==============================] - 61s 137ms/step - loss: 0.0700 - accuracy: 0.9772 - val_loss: 0.1210 - val_accuracy: 0.9661\n",
            "Epoch 24/30\n",
            "450/450 [==============================] - 62s 137ms/step - loss: 0.0696 - accuracy: 0.9758 - val_loss: 0.1627 - val_accuracy: 0.9528\n",
            "Epoch 25/30\n",
            "450/450 [==============================] - 60s 134ms/step - loss: 0.0836 - accuracy: 0.9718 - val_loss: 0.1293 - val_accuracy: 0.9611\n",
            "Epoch 26/30\n",
            "450/450 [==============================] - 60s 134ms/step - loss: 0.0644 - accuracy: 0.9784 - val_loss: 0.1590 - val_accuracy: 0.9544\n",
            "Epoch 27/30\n",
            "450/450 [==============================] - 60s 133ms/step - loss: 0.0739 - accuracy: 0.9751 - val_loss: 0.1127 - val_accuracy: 0.9672\n",
            "Epoch 28/30\n",
            "450/450 [==============================] - 60s 133ms/step - loss: 0.0585 - accuracy: 0.9800 - val_loss: 0.1093 - val_accuracy: 0.9750\n",
            "Epoch 29/30\n",
            "450/450 [==============================] - 60s 134ms/step - loss: 0.0685 - accuracy: 0.9785 - val_loss: 0.1257 - val_accuracy: 0.9628\n",
            "Epoch 30/30\n",
            "450/450 [==============================] - 60s 133ms/step - loss: 0.0582 - accuracy: 0.9804 - val_loss: 0.1179 - val_accuracy: 0.9694\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f44ea691610>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model\n",
        "model.save('/content/gdrive/MyDrive/MajorProject/br35hdataset/imagepreprocess_cnn.h5')"
      ],
      "metadata": {
        "id": "c2leFRFHQxFG"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model on test set\n",
        "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
        "print('Test accuracy:', test_accuracy)"
      ],
      "metadata": {
        "id": "hWT7rKlwH9R3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d8ebb57-b926-40cf-c918-9cc2509544a6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "57/57 [==============================] - 2s 42ms/step - loss: 0.1400 - accuracy: 0.9639\n",
            "Test accuracy: 0.9638888835906982\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "# Load saved CNN model\n",
        "cnn_model = load_model('/content/gdrive/MyDrive/MajorProject/br35hdataset/imagepreprocess_cnn.h5')"
      ],
      "metadata": {
        "id": "ZeiqOH_FxAdB"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import svm\n",
        "\n",
        "# Extract features using CNN model\n",
        "train_features = cnn_model.predict(train_images)\n",
        "test_features = cnn_model.predict(test_images)\n",
        "validation_features = cnn_model.predict(validation_images)\n",
        "\n",
        "# Train SVM classifier using CNN features\n",
        "clf = svm.SVC()\n",
        "#history = clf.fit(train_features, train_labels)\n",
        "\n",
        "# Evaluate SVM classifier on test set\n",
        "#accuracy = clf.score(test_features, test_labels)\n",
        "#print('Accuracy:', accuracy)\n",
        "\n",
        "# Initialize empty lists to store training and validation accuracies\n",
        "train_accs = []\n",
        "val_accs = []\n",
        "\n",
        "# Train SVM classifier using CNN features\n",
        "for epoch in range(EPOCHS):\n",
        "    clf.fit(train_features, train_labels)\n",
        "    train_acc = clf.score(train_features, train_labels)\n",
        "    val_acc = clf.score(validation_features, validation_labels)\n",
        "    train_accs.append(train_acc)\n",
        "    val_accs.append(val_acc)\n",
        "\n",
        "    # Print epoch number and accuracy values\n",
        "    print(f\"Epoch {epoch+1}: Train acc = {train_acc:.4f}, Val acc = {val_acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NgpZRFyNzmKK",
        "outputId": "d96d89bf-c7f1-4f24-adb0-cfc3fc5fc040"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/structured_function.py:256: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "450/450 [==============================] - 19s 30ms/step\n",
            "57/57 [==============================] - 2s 33ms/step\n",
            "57/57 [==============================] - 2s 31ms/step\n",
            "Epoch 1: Train acc = 0.9981, Val acc = 0.9700\n",
            "Epoch 2: Train acc = 0.9981, Val acc = 0.9700\n",
            "Epoch 3: Train acc = 0.9981, Val acc = 0.9700\n",
            "Epoch 4: Train acc = 0.9981, Val acc = 0.9700\n",
            "Epoch 5: Train acc = 0.9981, Val acc = 0.9700\n",
            "Epoch 6: Train acc = 0.9981, Val acc = 0.9700\n",
            "Epoch 7: Train acc = 0.9981, Val acc = 0.9700\n",
            "Epoch 8: Train acc = 0.9981, Val acc = 0.9700\n",
            "Epoch 9: Train acc = 0.9981, Val acc = 0.9700\n",
            "Epoch 10: Train acc = 0.9981, Val acc = 0.9700\n",
            "Epoch 11: Train acc = 0.9981, Val acc = 0.9700\n",
            "Epoch 12: Train acc = 0.9981, Val acc = 0.9700\n",
            "Epoch 13: Train acc = 0.9981, Val acc = 0.9700\n",
            "Epoch 14: Train acc = 0.9981, Val acc = 0.9700\n",
            "Epoch 15: Train acc = 0.9981, Val acc = 0.9700\n",
            "Epoch 16: Train acc = 0.9981, Val acc = 0.9700\n",
            "Epoch 17: Train acc = 0.9981, Val acc = 0.9700\n",
            "Epoch 18: Train acc = 0.9981, Val acc = 0.9700\n",
            "Epoch 19: Train acc = 0.9981, Val acc = 0.9700\n",
            "Epoch 20: Train acc = 0.9981, Val acc = 0.9700\n",
            "Epoch 21: Train acc = 0.9981, Val acc = 0.9700\n",
            "Epoch 22: Train acc = 0.9981, Val acc = 0.9700\n",
            "Epoch 23: Train acc = 0.9981, Val acc = 0.9700\n",
            "Epoch 24: Train acc = 0.9981, Val acc = 0.9700\n",
            "Epoch 25: Train acc = 0.9981, Val acc = 0.9700\n",
            "Epoch 26: Train acc = 0.9981, Val acc = 0.9700\n",
            "Epoch 27: Train acc = 0.9981, Val acc = 0.9700\n",
            "Epoch 28: Train acc = 0.9981, Val acc = 0.9700\n",
            "Epoch 29: Train acc = 0.9981, Val acc = 0.9700\n",
            "Epoch 30: Train acc = 0.9981, Val acc = 0.9700\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "# Save SVM classifier\n",
        "with open('/content/gdrive/MyDrive/MajorProject/br35hdataset/svm_model.pkl', 'wb') as f:\n",
        "    pickle.dump(clf, f)"
      ],
      "metadata": {
        "id": "jWbSnueC2tOH"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load SVM classifier\n",
        "with open('/content/gdrive/MyDrive/MajorProject/br35hdataset/svm_model.pkl', 'rb') as f:\n",
        "    svm_classifier = pickle.load(f)"
      ],
      "metadata": {
        "id": "2ISGtHwU0Hfx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training and validation accuracies\n",
        "plt.plot(train_accs, label='Training Accuracy')\n",
        "plt.plot(val_accs, label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VAu5WCbu0IXF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "51b72250-269b-4c22-fb9d-727f97b00711"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAEWCAYAAABIVsEJAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAAnTklEQVR4nO3deZhU1bnv8e9PQBHBAZo40Ch4HBACzdCCM6AxD0YFRRyIEzFxIINHvRpRk2hIOJqEm8ET4znEkYSIRqPBG6cwiQkaaRQVUAwqCeAQREEIGhne+8fe3Snaru7qbRfdTf8+z1MPe6+99qp3VUG9rL2q1lZEYGZmVl87NHYAZmbWPDmBmJlZJk4gZmaWiROImZll4gRiZmaZOIGYmVkmTiD2qUl6VNL5DV23MUlaJulzRWh3tqSvpNtnS3qikLoZnmdfSesltcoaq1ldnEBaqPTDpfKxRdKHOftn16etiDghIu5u6LpNkaRxkubUUF4i6WNJny20rYiYEhGfb6C4tkp4EfH3iGgfEZsbov0ank+SXpe0uBjtW/PgBNJCpR8u7SOiPfB34OScsimV9SS1brwom6RfA0dI6l6t/CzgpYhY2AgxNYZjgM8A+0s6dFs+sf9ONh1OILYVSUMkrZB0taS3gTsl7SHp/0laJen9dLs055zcyzJjJP1J0sS07huSTshYt7ukOZLWSZou6RZJv84TdyExfk/Sn9P2npBUknP8XEl/k7Ra0nX5Xp+IWAHMBM6tdug8YHJdcVSLeYykP+XsHy/pFUlrJf0cUM6x/5A0M43vXUlTJO2eHvsVsC/wcDqC/KakbpKi8sNW0j6Spkl6T9JSSRfmtH2DpPskTU5fm0WSyvO9Bqnzgd8Dj6Tbuf3qJemP6XO9I+natLyVpGslvZY+z3xJXavHmtat/vfkz5J+Imk1cENtr0d6TldJv0vfh9WSfi5pxzSm3jn1PiNpg6TOdfTXauAEYjXZC+gI7AdcRPL35M50f1/gQ+DntZw/CFgClAA/BG6XpAx1fwM8C3QCbuCTH9q5Conxi8CXSP7nvCNwJYCknsCtafv7pM9X44d+6u7cWCQdDPRN463va1XZRgnwO+BbJK/Fa8CRuVWAG9P4DgG6krwmRMS5bD2K/GENTzEVWJGePwr4L0nH5hwfntbZHZhWW8yS2qVtTEkfZ0naMT3WAZgOPJY+1wHAjPTUK4DRwBeAXYELgA21vS45BgGvA3sCE6jl9VAy7/P/gL8B3YAuwNSI+Djt4zk57Y4GZkTEqgLjsFwR4UcLfwDLgM+l20OAj4G2tdTvC7yfsz8b+Eq6PQZYmnOsHRDAXvWpS/Lhuwlol3P818CvC+xTTTF+K2f/q8Bj6fZ3SD5gKo/tkr4Gn8vTdjvgA+CIdH8C8PuMr9Wf0u3zgGdy6onkA/8redo9BXi+pvcw3e+WvpatST5cNwMdco7fCNyVbt8ATM851hP4sJbX9hxgVdp2W2AtcGp6bHRuXNXOWwKMqKG8KtZaXqe/1/F+V70ewOGV8dVQbxBJslW6XwGcUex/Y9vrwyMQq8mqiPiockdSO0n/m17i+QCYA+yu/N/webtyIyIq/4fZvp519wHeyykDWJ4v4AJjfDtne0NOTPvkth0R/wRW53uuNKbfAuelo6Wzgcn1iKMm1WOI3H1Je0qaKmll2u6vSUYqhah8LdfllP2N5H/mlaq/Nm2Vf67hfOC+iNiU/j15gH9fxupKMnqqSW3H6rLVe1/H69EV+FtEbKreSET8haR/QyT1IBkhTcsYU4vnBGI1qb5E8/8BDgYGRcSuJBOokHONvgjeAjqml0sqda2l/qeJ8a3cttPn7FTHOXcDZwDHAx2Ahz9lHNVjEFv3979I3pfeabvnVGuztmW13yR5LTvklO0LrKwjpk9I53OOBc6R9LaSebJRwBfSy3DLgf3znL4c+I8ayv+Z/pn7Xu9VrU71/tX2eiwH9q0lAd6d1j8XuD/3P0tWP04gVogOJNfy10jqCFxf7CeMiL+RXF64IZ38PBw4uUgx3g+cJOmo9Fr+eOr+t/EUsAaYxL+vr3+aOP4A9JI0Mv3gu5StP0Q7AOuBtZK6AFdVO/8d8nxwR8RyYC5wo6S2kvoAXyb5X3t9nQu8SpIk+6aPg0gut40mmXvYW9JlknaS1EHSoPTc24DvSTpQiT6SOkUy/7CSJCm1knQBNSeaXLW9Hs+SJOSbJO2S9jl3PunXwKkkSWRyhtfAUk4gVoifAjsD7wLPkEyQbgtnk1zPXg18H7gX+Feeuj8lY4wRsQj4Gskk+FvA+yQfiLWdEyQfPvux9YdQpjgi4l3gdOAmkv4eCPw5p8p3gf4k8w1/IJlwz3Uj8C1JayRdWcNTjCaZa3gTeBC4PiKmFxJbNecDv4iIt3MfwP8A56eXyY4nSfZvA38Fhqbn/hi4D3iCZA7pdpLXCuBCkiSwGuhFkvBqk/f1iOS3LyeTXJ76O8l7eWbO8eXAcyQjmKfq/xJYpcqJJLMmT9K9wCsRUfQRkG3fJN0BvBkR32rsWJozJxBrspT8QO094A3g88BDwOER8XxjxmXNm6RuwAKgX0S80bjRNG++hGVN2V4kX+dcD9wMjHXysE9D0veAhcCPnDw+PY9AzMwsE49AzMwskxaxKFlJSUl069atscMwM2tW5s+f/25E5F0nrEUkkG7dulFRUdHYYZiZNSuS/lbbcV/CMjOzTJxAzMwsEycQMzPLxAnEzMwycQIxM7NMnEDMzCwTJxAzM8ukRfwOJKvvPryIxW9+0NhhmJll0nOfXbn+5F5Fa98jEDMzy8QjkFoUM3ObmTV3HoGYmVkmTiBmZpaJE4iZmWXiBGJmZpk4gZiZWSZOIGZmlokTiJmZZeIEYmZmmTiBmJlZJk4gZmaWiROImZll4gRiZmaZOIGYmVkmTiBmZpaJE4iZmWXiBGJmZpk4gZiZWSZFTSCShklaImmppHE1HN9P0gxJL0qaLak059gPJC1MH2fmlN8l6Q1JC9JH32L2wczMala0BCKpFXALcALQExgtqWe1ahOByRHRBxgP3JieeyLQH+gLDAKulLRrznlXRUTf9LGgWH0wM7P8ijkCGQgsjYjXI+JjYCowolqdnsDMdHtWzvGewJyI2BQR/wReBIYVMVYzM6unYiaQLsDynP0VaVmuF4CR6fapQAdJndLyYZLaSSoBhgJdc86bkF72+omknWp6ckkXSaqQVLFq1aqG6I+ZmeVo7En0K4HBkp4HBgMrgc0R8QTwCDAXuAd4GticnnMN0AM4FOgIXF1TwxExKSLKI6K8c+fOxe2FmVkLVMwEspKtRw2laVmViHgzIkZGRD/gurRsTfrnhHSO43hAwKtp+VuR+BdwJ8mlMjMz28aKmUDmAQdK6i5pR+AsYFpuBUklkipjuAa4Iy1vlV7KQlIfoA/wRLq/d/qngFOAhUXsg5mZ5dG6WA1HxCZJXwceB1oBd0TEIknjgYqImAYMAW6UFMAc4Gvp6W2Ap5IcwQfAORGxKT02RVJnklHJAuCSYvXBzMzyU0Q0dgxFV15eHhUVFY0dhplZsyJpfkSU5zve2JPoZmbWTDmBmJlZJk4gZmaWiROImZll4gRiZmaZOIGYmVkmTiBmZpaJE4iZmWXiBGJmZpk4gZiZWSZOIGZmlokTiJmZZeIEYmZmmTiBmJlZJk4gZmaWiROImZll4gRiZmaZOIGYmVkmTiBmZpaJE4iZmWXiBGJmZpk4gZiZWSZOIGZmlokTiJmZZeIEYmZmmTiBmJlZJkVNIJKGSVoiaamkcTUc30/SDEkvSpotqTTn2A8kLUwfZ+aUd5f0l7TNeyXtWMw+mJlZzYqWQCS1Am4BTgB6AqMl9axWbSIwOSL6AOOBG9NzTwT6A32BQcCVknZNz/kB8JOIOAB4H/hysfpgZmb5FXMEMhBYGhGvR8THwFRgRLU6PYGZ6fasnOM9gTkRsSki/gm8CAyTJOBY4P603t3AKcXrgpmZ5VPMBNIFWJ6zvyIty/UCMDLdPhXoIKlTWj5MUjtJJcBQoCvQCVgTEZtqaRMASRdJqpBUsWrVqgbpkJmZ/VtjT6JfCQyW9DwwGFgJbI6IJ4BHgLnAPcDTwOb6NBwRkyKiPCLKO3fu3MBhm5lZMRPISpJRQ6XStKxKRLwZESMjoh9wXVq2Jv1zQkT0jYjjAQGvAquB3SW1ztemmZltG8VMIPOAA9NvTe0InAVMy60gqURSZQzXAHek5a3SS1lI6gP0AZ6IiCCZKxmVnnM+8Psi9sHMzPIoWgJJ5ym+DjwOvAzcFxGLJI2XNDytNgRYIulVYE9gQlreBnhK0mJgEnBOzrzH1cAVkpaSzIncXqw+mJlZfkr+U799Ky8vj4qKisYOw8ysWZE0PyLK8x1v7El0MzNrppxAzMwsEycQMzPLxAnEzMwycQIxM7NMnEDMzCwTJxAzM8vECcTMzDJxAjEzs0ycQMzMLBMnEDMzy8QJxMzMMnECMTOzTJxAzMwsEycQMzPLxAnEzMwyqTOBSDo557azZmZmQGEjkDOBv0r6oaQexQ7IzMyahzoTSEScA/QDXgPukvS0pIskdSh6dGZm1mQVdGkqIj4A7gemAnsDpwLPSfpGEWMzM7MmrHVdFSQNB74EHABMBgZGxD8ktQMWA/9d3BDNrKFs3LiRFStW8NFHHzV2KNaEtG3bltLSUtq0aVOv8+pMIMBpwE8iYk5uYURskPTlej2bmTWqFStW0KFDB7p164akxg7HmoCIYPXq1axYsYLu3bvX69xCLmHdADxbuSNpZ0nd0ieeUa9nM7NG9dFHH9GpUycnD6siiU6dOmUalRaSQH4LbMnZ35yWmVkz5ORh1WX9O1FIAmkdER9X7qTbO2Z6NjNr0VavXk3fvn3p27cve+21F126dKna//jjj2s9t6KigksvvbTO5zjiiCMaKlwALrvsMrp06cKWLVvqrtzCFDIHskrS8IiYBiBpBPBuccMys+1Rp06dWLBgAQA33HAD7du358orr6w6vmnTJlq3rvljqby8nPLy8jqfY+7cuQ0SK8CWLVt48MEH6dq1K08++SRDhw5tsLZz1dbvpqyQEcglwLWS/i5pOXA1cHEhjUsaJmmJpKWSxtVwfD9JMyS9KGm2pNKcYz+UtEjSy5JuVjrGSustkbQgfXymsK6aWVM0ZswYLrnkEgYNGsQ3v/lNnn32WQ4//HD69evHEUccwZIlSwCYPXs2J510EpAknwsuuIAhQ4aw//77c/PNN1e11759+6r6Q4YMYdSoUfTo0YOzzz6biADgkUceoUePHgwYMIBLL720qt3qZs+eTa9evRg7diz33HNPVfk777zDqaeeSllZGWVlZVVJa/LkyfTp04eysjLOPffcqv7df//9NcZ39NFHM3z4cHr27AnAKaecwoABA+jVqxeTJk2qOuexxx6jf//+lJWVcdxxx7FlyxYOPPBAVq1aBSSJ7oADDqja31bqTHkR8RpwmKT26f76QhqW1Aq4BTgeWAHMkzQtIhbnVJsITI6IuyUdC9wInCvpCOBIoE9a70/AYGB2un92RFQUEoeZ1ey7Dy9i8ZsfNGibPffZletP7lXv81asWMHcuXNp1aoVH3zwAU899RStW7dm+vTpXHvttTzwwAOfOOeVV15h1qxZrFu3joMPPpixY8d+4muozz//PIsWLWKfffbhyCOP5M9//jPl5eVcfPHFzJkzh+7duzN69Oi8cd1zzz2MHj2aESNGcO2117Jx40batGnDpZdeyuDBg3nwwQfZvHkz69evZ9GiRXz/+99n7ty5lJSU8N5779XZ7+eee46FCxdWffvpjjvuoGPHjnz44YcceuihnHbaaWzZsoULL7ywKt733nuPHXbYgXPOOYcpU6Zw2WWXMX36dMrKyujcuXM9X/lPp6AfEko6EfgqcIWk70j6TgGnDQSWRsTr6bzJVGBEtTo9gZnp9qyc4wG0JZlr2QloA7xTSKxm1vycfvrptGrVCoC1a9dy+umn89nPfpbLL7+cRYsW1XjOiSeeyE477URJSQmf+cxneOedT35EDBw4kNLSUnbYYQf69u3LsmXLeOWVV9h///2rPrTzJZCPP/6YRx55hFNOOYVdd92VQYMG8fjjjwMwc+ZMxo4dC0CrVq3YbbfdmDlzJqeffjolJSUAdOzYsc5+Dxw4cKuvzt58882UlZVx2GGHsXz5cv7617/yzDPPcMwxx1TVq2z3ggsuYPLkyUCSeL70pS/V+XwNrZAfEv4P0A4YCtwGjCLna7216AIsz9lfAQyqVucFYCTwM5Jft3eQ1CkinpY0C3gLEPDziHg557w7JW0GHgC+H5Xj0q3jvgi4CGDfffctIFyzliXLSKFYdtlll6rtb3/72wwdOpQHH3yQZcuWMWTIkBrP2Wmnnaq2W7VqxaZNmzLVyefxxx9nzZo19O7dG4ANGzaw8847573clU/r1q2rJuC3bNmy1ZcFcvs9e/Zspk+fztNPP027du0YMmRIrV+t7dq1K3vuuSczZ87k2WefZcqUKfWKqyEUMgI5IiLOA96PiO8ChwMHNdDzXwkMlvQ8ySWqlcBmSQcAhwClJInoWElHp+ecHRG9gaPTx7k1NRwRkyKiPCLKt/WwzsyyW7t2LV26dAHgrrvuavD2Dz74YF5//XWWLVsGwL333ltjvXvuuYfbbruNZcuWsWzZMt544w3++Mc/smHDBo477jhuvfVWADZv3szatWs59thj+e1vf8vq1asBqi5hdevWjfnz5wMwbdo0Nm7cWOPzrV27lj322IN27drxyiuv8MwzzwBw2GGHMWfOHN54442t2gX4yle+wjnnnLPVCG5bKiSBVKbADZL2ATaSrIdVl5VA15z90rSsSkS8GREjI6IfcF1atoZkNPJMRKxP51weJUlcRMTK9M91wG9ILpWZ2Xbim9/8Jtdccw39+vWr14ihUDvvvDO/+MUvGDZsGAMGDKBDhw7stttuW9XZsGEDjz32GCeeeGJV2S677MJRRx3Fww8/zM9+9jNmzZpF7969GTBgAIsXL6ZXr15cd911DB48mLKyMq644goALrzwQp588knKysp4+umntxp15Bo2bBibNm3ikEMOYdy4cRx22GEAdO7cmUmTJjFy5EjKyso488wzq84ZPnw469evb5TLV0DyM/baHsC3gd1JljR5m+Sy0vgCzmsNvA50J5nLeAHoVa1OCbBDuj2hsl2SJeSnp220AWYAJ6f7JWmdNiQLPF5SVywDBgwIM4tYvHhxY4fQJKxbty4iIrZs2RJjx46NH//4x40cUTbz5s2Lo446qkHaqunvBlARtXy21joCSW8kNSMi1kTEA8B+QI+IqHMSPSI2AV8HHgdeBu6LiEWSxqcLNAIMAZZIehXYM00ipInhNeClNPG8EBEPk0yoPy7pRWAByYjml3XFYmaW65e//CV9+/alV69erF27losvLuiXCU3KTTfdxGmnncaNN97YaDEoPjn/vHUF6flILjE1W+Xl5VFR4W/9mr388ssccsghjR2GNUE1/d2QND8i8v56s5A5kBmSTqv8IZ+ZmRkUlkAuJlk88V+SPpC0TlLD/vrIzMyanUJ+ie5b15qZ2ScU8kPCY2oqj2o3mDIzs5alkEtYV+U8vg08THKTKTOzehk6dGjVciCVfvrTn1YtC1KTIUOGUPklmC984QusWbPmE3VuuOEGJk6cWOtzP/TQQyxe/O+l+L7zne8wffr0ekRfu5a47HudCSQiTs55HA98Fni/+KGZ2fZm9OjRTJ06dauyqVOn1rqgYa5HHnmE3XffPdNzV08g48eP53Of+1ymtqqrvux7sRTjh5WfRkGLKVazgmSZETOzehk1ahR/+MMfqtaDWrZsGW+++SZHH300Y8eOpby8nF69enH99dfXeH63bt14993kdkQTJkzgoIMO4qijjqpa8h2S33gceuihlJWVcdppp7Fhwwbmzp3LtGnTuOqqq+jbty+vvfbaVsusz5gxg379+tG7d28uuOAC/vWvf1U93/XXX0///v3p3bs3r7zySo1xtdRl3wuZA/lvktVxIUk4fYHnGuTZzazxPDoO3n6pYdvcqzeccFPewx07dmTgwIE8+uijjBgxgqlTp3LGGWcgiQkTJtCxY0c2b97Mcccdx4svvkifPn1qbGf+/PlMnTqVBQsWsGnTJvr378+AAQMAGDlyJBdeeCEA3/rWt7j99tv5xje+wfDhwznppJMYNWrUVm199NFHjBkzhhkzZnDQQQdx3nnnceutt3LZZZcBUFJSwnPPPccvfvELJk6cyG233faJeFrqsu+FjEAqgPnp42ng6og4p0Ge3cxanNzLWLmXr+677z769+9Pv379WLRo0VaXm6p76qmnOPXUU2nXrh277rorw4cPrzq2cOFCjj76aHr37s2UKVPyLgdfacmSJXTv3p2DDkrWiD3//POZM+ff3xEaOXIkAAMGDKhagDFXS172vZB7KN4PfBQRmyG5UZSkdhGxocGiMLNtr5aRQjGNGDGCyy+/nOeee44NGzYwYMAA3njjDSZOnMi8efPYY489GDNmTK1LmddmzJgxPPTQQ5SVlXHXXXcxe/bsTxVv5ZLw+ZaDb8nLvhf0S3Rg55z9nUkWOjQzq7f27dszdOhQLrjggqrRxwcffMAuu+zCbrvtxjvvvMOjjz5aaxvHHHMMDz30EB9++CHr1q3j4Ycfrjq2bt069t57bzZu3LjVh2WHDh1Yt27dJ9o6+OCDWbZsGUuXLgXgV7/6FYMHDy64Py152fdCEkjbyLmNbbrdrsEiMLMWZ/To0bzwwgtVCaSsrIx+/frRo0cPvvjFL3LkkUfWen7//v0588wzKSsr44QTTuDQQw+tOva9732PQYMGceSRR9KjR4+q8rPOOosf/ehH9OvXj9dee62qvG3bttx5552cfvrp9O7dmx122IFLLrmkoH609GXfC1lM8c/ANyLiuXR/AMkdAg9v0EiKyIspmiW8mGLLVFFRweWXX85TTz2Vt06WxRQLmQO5DPitpDdJbi+7F8n9OszMrIm76aabuPXWW4tyy9tC1sKaJ6kHcHBatCQiar44Z2ZmTcq4ceMYN25cUdqucw5E0teAXSJiYUQsBNpL+mpRojEzs2ajkEn0CyO5TzkAEfE+cGHRIjKzoqpr3tNanqx/JwpJIK1ybyYlqRXJPc7NrJlp27Ytq1evdhKxKhHB6tWradu2bb3PLWQS/THgXkn/m+5fDNT+JW0za5JKS0tZsWJFg62FZNuHtm3bUlpaWu/zCkkgVwMXAZVfjH6R5JtYZtbMtGnTZqslMcw+jUKWc98C/AVYBgwEjgVeLm5YZmbW1OUdgUg6CBidPt4F7gWIiKHbJjQzM2vKaruE9QrwFHBSRCwFkHT5NonKzMyavNouYY0E3gJmSfqlpONIfoluZmaWP4FExEMRcRbQA5hFsqTJZyTdKunz2yg+MzNrogqZRP9nRPwmIk4GSoHnSb6ZZWZmLVi97okeEe9HxKSIOK6Q+pKGSVoiaamkTyzGImk/STMkvShptqTSnGM/lLRI0suSbq78MaOkAZJeStu8OfdHjmZmtu3UK4HUR/qL9VuAE4CewGhJPatVmwhMjog+wHjgxvTcI4AjgT7AZ4FDgco7vNxKspTKgeljWLH6YGZm+RUtgZD8ZmRpRLweER8DU4ER1er0BGam27NyjgfQlmTJlJ2ANsA7kvYGdo2IZyJZi2EycEoR+2BmZnkUM4F0AZbn7K9Iy3K9QPJtL4BTgQ6SOkXE0yQJ5a308XhEvJyev6KONs3MbBsoZgIpxJXAYEnPk1yiWglslnQAcAjJpH0X4FhJR9enYUkXSaqQVOF1f8zMGl4xE8hKoGvOfmlaViUi3oyIkRHRD7guLVtDMhp5JiLWp/dgfxQ4PD2/tLY2c9qeFBHlEVHeuXPnBuqSmZlVKmYCmQccKKm7pB2Bs4BpuRUklUiqjOEa4I50++8kI5PWktqQjE5ejoi3gA8kHZZ+++o84PdF7IOZmeVRtAQSEZuArwOPkyy+eF9ELJI0XtLwtNoQYImkV4E9gQlp+f3Aa8BLJPMkL0TEw+mxrwK3AUvTOl5a3sysEagl3FimvLw8KioqGjsMM7NmRdL8iCjPd7yxJ9HNzKyZcgIxM7NMnEDMzCwTJxAzM8vECcTMzDJxAjEzs0ycQMzMLBMnEDMzy8QJxMzMMnECMTOzTJxAzMwsEycQMzPLxAnEzMwycQIxM7NMnEDMzCwTJxAzM8vECcTMzDJxAjEzs0ycQMzMLBMnEDMzy8QJxMzMMnECMTOzTJxAzMwsEycQMzPLxAnEzMwycQIxM7NMnEDMzCyToiYQScMkLZG0VNK4Go7vJ2mGpBclzZZUmpYPlbQg5/GRpFPSY3dJeiPnWN9i9sHMzGrWulgNS2oF3AIcD6wA5kmaFhGLc6pNBCZHxN2SjgVuBM6NiFlA37SdjsBS4Imc866KiPuLFbuZmdWtmCOQgcDSiHg9Ij4GpgIjqtXpCcxMt2fVcBxgFPBoRGwoWqRmZlZvxUwgXYDlOfsr0rJcLwAj0+1TgQ6SOlWrcxZwT7WyCellr59I2qmmJ5d0kaQKSRWrVq3K1gMzM8ursSfRrwQGS3oeGAysBDZXHpS0N9AbeDznnGuAHsChQEfg6poajohJEVEeEeWdO3cuUvhmZi1X0eZASJJB15z90rSsSkS8SToCkdQeOC0i1uRUOQN4MCI25pzzVrr5L0l3kiQhMzPbxoo5ApkHHCipu6QdSS5FTcutIKlEUmUM1wB3VGtjNNUuX6WjEiQJOAVY2PChm5lZXYqWQCJiE/B1kstPLwP3RcQiSeMlDU+rDQGWSHoV2BOYUHm+pG4kI5gnqzU9RdJLwEtACfD9YvXBzMzyU0Q0dgxFV15eHhUVFY0dhplZsyJpfkSU5zve2JPoZmbWTDmBmJlZJk4gZmaWiROImZll4gRiZmaZOIGYmVkmTiBmZpaJE4iZmWXiBGJmZpk4gZiZWSZOIGZmlokTiJmZZeIEYmZmmTiBmJlZJk4gZmaWiROImZll4gRiZmaZOIGYmVkmTiBmZpaJE4iZmWXiBGJmZpk4gZiZWSZOIGZmlokTiJmZZeIEYmZmmTiBmJlZJkVNIJKGSVoiaamkcTUc30/SDEkvSpotqTQtHyppQc7jI0mnpMe6S/pL2ua9knYsZh/MzKxmRUsgkloBtwAnAD2B0ZJ6Vqs2EZgcEX2A8cCNABExKyL6RkRf4FhgA/BEes4PgJ9ExAHA+8CXi9UHMzPLr3UR2x4ILI2I1wEkTQVGAItz6vQErki3ZwEP1dDOKODRiNggSSQJ5YvpsbuBG4BbGzp4AB4dB2+/VJSmzcyKbq/ecMJNRWu+mJewugDLc/ZXpGW5XgBGptunAh0kdapW5yzgnnS7E7AmIjbV0iYAki6SVCGpYtWqVRm7YGZm+RRzBFKIK4GfSxoDzAFWApsrD0raG+gNPF7fhiNiEjAJoLy8PDJFV8TMbWbW3BUzgawEuubsl6ZlVSLiTdIRiKT2wGkRsSanyhnAgxGxMd1fDewuqXU6CvlEm2Zmtm0U8xLWPODA9FtTO5JcipqWW0FSiaTKGK4B7qjWxmj+ffmKiAiSuZJRadH5wO+LELuZmdWhaAkkHSF8neTy08vAfRGxSNJ4ScPTakOAJZJeBfYEJlSeL6kbyQjmyWpNXw1cIWkpyZzI7cXqg5mZ5afkP/Xbt/Ly8qioqGjsMMzMmhVJ8yOiPN9x/xLdzMwycQIxM7NMnEDMzCwTJxAzM8ukRUyiS1oF/C3j6SXAuw0YTlOwvfXJ/Wn6trc+bW/9gZr7tF9EdM53QotIIJ+GpIravoXQHG1vfXJ/mr7trU/bW38gW598CcvMzDJxAjEzs0ycQOo2qbEDKILtrU/uT9O3vfVpe+sPZOiT50DMzCwTj0DMzCwTJxAzM8vECaQWkoZJWiJpqaRxjR3PpyVpmaSXJC2Q1CxXl5R0h6R/SFqYU9ZR0h8l/TX9c4/GjLE+8vTnBkkr0/dpgaQvNGaM9SGpq6RZkhZLWiTpP9Py5vwe5etTs3yfJLWV9KykF9L+fDct7y7pL+nn3b3pbThqb8tzIDWT1Ap4FTie5Na584DREbG41hObMEnLgPKIaLY/gJJ0DLAemBwRn03Lfgi8FxE3pYl+j4i4ujHjLFSe/twArI+IiY0ZWxbpXUT3jojnJHUA5gOnAGNovu9Rvj6dQTN8nyQJ2CUi1ktqA/wJ+E/gCuB3ETFV0v8AL0TErbW15RFIfgOBpRHxekR8DEwFRjRyTC1eRMwB3qtWPAK4O92+m+Qfd7OQpz/NVkS8FRHPpdvrSO4F1IXm/R7l61OzFIn16W6b9BHAscD9aXlB75ETSH5dgOU5+ytoxn9pUgE8IWm+pIsaO5gGtGdEvJVuv01yc7Lm7uuSXkwvcTWbyz250pvC9QP+wnbyHlXrEzTT90lSK0kLgH8AfwReA9akNwKEAj/vnEBalqMioj9wAvC19PLJdiW97XFzvy57K/AfQF/gLeD/Nmo0GUhqDzwAXBYRH+Qea67vUQ19arbvU0Rsjoi+QCnJ1ZYeWdpxAslvJcktdSuVpmXNVkSsTP/8B/AgyV+c7cE76XXqyuvV/2jkeD6ViHgn/Qe+Bfglzex9Sq+rPwBMiYjfpcXN+j2qqU/N/X0CiIg1wCzgcGB3Sa3TQwV93jmB5DcPODD9ZsKOwFnAtEaOKTNJu6QTgEjaBfg8sLD2s5qNacD56fb5wO8bMZZPrfKDNnUqzeh9Sidobwdejogf5xxqtu9Rvj411/dJUmdJu6fbO5N8UehlkkQyKq1W0Hvkb2HVIv1a3k+BVsAdETGhcSPKTtL+JKMOgNbAb5pjfyTdAwwhWXr6HeB64CHgPmBfkmX7z4iIZjExnac/Q0guiwSwDLg4Z/6gSZN0FPAU8BKwJS2+lmTOoLm+R/n6NJpm+D5J6kMySd6KZBBxX0SMTz8jpgIdgeeBcyLiX7W25QRiZmZZ+BKWmZll4gRiZmaZOIGYmVkmTiBmZpaJE4iZmWXiBGLWACRtzlmVdUFDrt4sqVvuar1mTUXruquYWQE+TJeGMGsxPAIxK6L0Hiw/TO/D8qykA9LybpJmpgvxzZC0b1q+p6QH03s1vCDpiLSpVpJ+md6/4Yn0F8RmjcoJxKxh7FztEtaZOcfWRkRv4OckKxsA/Ddwd0T0AaYAN6flNwNPRkQZ0B9YlJYfCNwSEb2ANcBpRe2NWQH8S3SzBiBpfUS0r6F8GXBsRLyeLsj3dkR0kvQuyU2KNqblb0VEiaRVQGnuEhLpEuJ/jIgD0/2rgTYR8f1t0DWzvDwCMSu+yLNdH7lrEm3G85fWBDiBmBXfmTl/Pp1uzyVZ4RngbJLF+gBmAGOh6qY/u22rIM3qy/+LMWsYO6d3eKv0WERUfpV3D0kvkowiRqdl3wDulHQVsAr4Ulr+n8AkSV8mGWmMJblZkVmT4zkQsyJK50DKI+Ldxo7FrKH5EpaZmWXiEYiZmWXiEYiZmWXiBGJmZpk4gZiZWSZOIGZmlokTiJmZZfL/AT33zYDXLE2wAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Replace labels 0 and 1 with \"no tumor\" and \"tumor\"\n",
        "label_names = np.array(['no tumor', 'tumor'])\n",
        "test_labels = label_names[test_labels]\n",
        "\n",
        "# Make predictions on test set\n",
        "test_predictions = clf.predict(test_features)\n",
        "\n",
        "# Replace labels 0 and 1 with \"no tumor\" and \"tumor\"\n",
        "label_names = np.array(['no tumor', 'tumor'])\n",
        "test_labels = label_names[test_labels]\n",
        "\n",
        "# Create confusion matrix\n",
        "cm = confusion_matrix(test_labels, test_predictions)\n",
        "\n",
        "# Plot confusion matrix using heatmap\n",
        "sns.heatmap(cm, annot=True, cmap='Blues')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "QEOu50Hs0y8x",
        "outputId": "aff649e9-2181-41b4-ceeb-3b9417b1611a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-add66d93fbc6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Replace labels 0 and 1 with \"no tumor\" and \"tumor\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mlabel_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'no tumor'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tumor'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mtest_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-T8KoFe14H7L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}